import pandas as pd
import json
from datetime import datetime

print("=" * 60)
print("ANIME DATA PREPROCESSING SCRIPT")
print("=" * 60)
print(f"Started: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")

# ============================================================================
# STEP 1: LOAD RAW DATA
# ============================================================================
print("STEP 1: Loading raw CSV data...")
df = pd.read_csv('top_15000_anime.csv')
print(f"âœ“ Loaded {len(df)} anime from Kaggle dataset")
print(f"  Columns: {', '.join(df.columns.tolist())}")
print()

# ============================================================================
# STEP 2: DATA CLEANING
# ============================================================================
print("STEP 2: Cleaning data...")
initial_count = len(df)

# Remove entries without score or genre (critical fields)
df = df.dropna(subset=['score', 'genres'])
print(f"âœ“ Removed {initial_count - len(df)} entries with missing score/genres")

# Remove entries with invalid scores
df = df[df['score'] > 0]
print(f"âœ“ Filtered to {len(df)} entries with valid scores")

# Fill missing episodes with 0
df['episodes'] = df['episodes'].fillna(0)
print(f"âœ“ Handled missing episode counts")

# Fill missing members with 0
df['members'] = df['members'].fillna(0)
print(f"âœ“ Handled missing member counts")
print()

# ============================================================================
# STEP 3: EXTRACT PRIMARY GENRE
# ============================================================================
print("STEP 3: Extracting primary genres...")
# Genres are comma-separated, take first one
df['primary_genre'] = df['genres'].str.split(',').str[0].str.strip()

unique_genres = df['primary_genre'].nunique()
print(f"âœ“ Extracted primary genre from multi-genre entries")
print(f"âœ“ Found {unique_genres} unique genres:")

# Show genre distribution
genre_counts = df['primary_genre'].value_counts()
for genre, count in genre_counts.head(10).items():
    print(f"  â€¢ {genre}: {count} anime")
print(f"  ... and {len(genre_counts) - 10} more genres")
print()

# ============================================================================
# STEP 4: CREATE EPISODE RANGES
# ============================================================================
print("STEP 4: Categorizing episode counts...")

def categorize_episodes(episodes):
    """
    Categorize anime by episode count into meaningful ranges.
    
    Args:
        episodes (int): Number of episodes
        
    Returns:
        str: Episode range category
    """
    if pd.isna(episodes) or episodes == 0:
        return "Unknown"
    elif episodes <= 12:
        return "1-12"
    elif episodes <= 26:
        return "13-26"
    elif episodes <= 52:
        return "27-52"
    elif episodes <= 100:
        return "53-100"
    elif episodes <= 200:
        return "101-200"
    else:
        return "200+"

df['episode_range'] = df['episodes'].apply(categorize_episodes)

# Show episode range distribution
range_counts = df['episode_range'].value_counts()
print(f"âœ“ Categorized anime into {len(range_counts)} episode ranges:")
for range_name, count in range_counts.items():
    print(f"  â€¢ {range_name} episodes: {count} anime")
print()

# ============================================================================
# STEP 5: SELECT TOP ANIME
# ============================================================================
print("STEP 5: Selecting top-rated anime...")
TARGET_COUNT = 2000

# Sort by score and take top N
top_anime = df.nlargest(TARGET_COUNT, 'score')

print(f"âœ“ Selected top {len(top_anime)} anime by rating")
print(f"  Score range: {top_anime['score'].min():.2f} - {top_anime['score'].max():.2f}")
print(f"  Most popular: {top_anime.nlargest(1, 'members')['name'].values[0]}")
print(f"  Highest rated: {top_anime.nlargest(1, 'score')['name'].values[0]}")
print()

# ============================================================================
# STEP 6: CREATE OPTIMIZED ANIME LIST
# ============================================================================
print("STEP 6: Creating optimized anime list...")

anime_list = []
for idx, row in top_anime.iterrows():
    # Use shortened keys to reduce file size
    anime_entry = {
        'n': row['name'],                                    # name
        'g': row['primary_genre'],                          # genre
        's': round(float(row['score']), 2),                 # score
        'e': int(row['episodes']) if pd.notna(row['episodes']) else 0,  # episodes
        'm': int(row['members']) if pd.notna(row['members']) else 0,    # members
        'r': row['episode_range']                           # range
    }
    anime_list.append(anime_entry)

print(f"âœ“ Created {len(anime_list)} optimized anime entries")
print(f"  Field name compression: 'name' â†’ 'n' (saves ~30% space)")
print()

# ============================================================================
# STEP 7: PRE-CALCULATE GENRE STATISTICS
# ============================================================================
print("STEP 7: Pre-calculating genre statistics...")

# Calculate average score and count per genre
genre_stats = df.groupby('primary_genre').agg({
    'score': 'mean',
    'anime_id': 'count'
}).round(2)

# Sort by average score
genre_stats = genre_stats.sort_values('score', ascending=False)

genre_data = {
    'labels': list(genre_stats.index),
    'scores': [round(score, 2) for score in genre_stats['score'].tolist()],
    'counts': genre_stats['anime_id'].tolist()
}

print(f"âœ“ Calculated stats for {len(genre_data['labels'])} genres")
print(f"  Top genre by rating: {genre_data['labels'][0]} ({genre_data['scores'][0]})")
print(f"  Most anime in genre: {genre_data['labels'][genre_data['counts'].index(max(genre_data['counts']))]} ({max(genre_data['counts'])} anime)")
print()

# ============================================================================
# STEP 8: PRE-CALCULATE EPISODE STATISTICS
# ============================================================================
print("STEP 8: Pre-calculating episode range statistics...")

# Calculate average score and count per episode range
episode_stats = df.groupby('episode_range').agg({
    'score': 'mean',
    'anime_id': 'count'
}).round(2)

# Define order for episode ranges
episode_order = ['1-12', '13-26', '27-52', '53-100', '101-200', '200+']

episode_data = {
    'labels': episode_order,
    'scores': [round(episode_stats.loc[label, 'score'], 2) if label in episode_stats.index else 0 
               for label in episode_order],
    'counts': [episode_stats.loc[label, 'anime_id'] if label in episode_stats.index else 0 
               for label in episode_order]
}

print(f"âœ“ Calculated stats for {len(episode_order)} episode ranges")
best_range = episode_order[episode_data['scores'].index(max(episode_data['scores']))]
print(f"  Best rated range: {best_range} episodes ({max(episode_data['scores'])} avg)")
print()

# ============================================================================
# STEP 9: PACKAGE DATA
# ============================================================================
print("STEP 9: Packaging final data structure...")

data_package = {
    'anime': anime_list,
    'genreStats': genre_data,
    'episodeStats': episode_data,
    'metadata': {
        'totalAnime': len(anime_list),
        'totalGenres': len(genre_data['labels']),
        'generatedAt': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'sourceDataset': 'Kaggle - Top 15,000 Ranked Anime Dataset'
    }
}

print(f"âœ“ Packaged data structure:")
print(f"  â€¢ {len(anime_list)} anime entries")
print(f"  â€¢ {len(genre_data['labels'])} genre stats")
print(f"  â€¢ {len(episode_data['labels'])} episode range stats")
print(f"  â€¢ Metadata included")
print()

# ============================================================================
# STEP 10: SAVE COMPRESSED JSON
# ============================================================================
print("STEP 10: Saving compressed JSON...")

# Save with minimal whitespace (no spaces, no indentation)
with open('anime_data_optimized.json', 'w', encoding='utf-8') as f:
    json.dump(data_package, f, separators=(',', ':'), ensure_ascii=False)

# Calculate file size
import os
file_size = os.path.getsize('anime_data_optimized.json')
file_size_kb = file_size / 1024

print(f"âœ“ Saved to: anime_data_optimized.json")
print(f"âœ“ File size: {file_size_kb:.1f} KB ({file_size:,} bytes)")
print()

# ============================================================================
# STEP 11: GENERATE SUMMARY STATISTICS
# ============================================================================
print("STEP 11: Summary statistics...")
print("-" * 60)

print("\nðŸ“Š DATA SUMMARY:")
print(f"  Total anime processed:     {len(anime_list):,}")
print(f"  Score range:               {min(a['s'] for a in anime_list):.2f} - {max(a['s'] for a in anime_list):.2f}")
print(f"  Average score:             {sum(a['s'] for a in anime_list) / len(anime_list):.2f}")
print(f"  Total genres:              {len(genre_data['labels'])}")
print(f"  Episode ranges:            {len(episode_data['labels'])}")

print("\nðŸ’¾ FILE OPTIMIZATION:")
print(f"  Original CSV size:         ~13 MB")
print(f"  Optimized JSON size:       {file_size_kb:.1f} KB")
print(f"  Compression ratio:         {(13 * 1024) / file_size_kb:.1f}x smaller")

print("\nâš¡ PERFORMANCE BENEFITS:")
print(f"  â€¢ Instant browser loading (<1 second)")
print(f"  â€¢ Pre-calculated statistics (no runtime computation)")
print(f"  â€¢ Optimized field names (30% size reduction)")
print(f"  â€¢ Ready for web deployment")

print("\n" + "=" * 60)
print("âœ… PREPROCESSING COMPLETE!")
print("=" * 60)
print(f"Finished: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print(f"\nOutput file: anime_data_optimized.json")
print("Ready to embed in HTML dashboard!")
